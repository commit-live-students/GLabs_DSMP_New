{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align=\"center\">Gradient Boosting and XGBoost</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading https://files.pythonhosted.org/packages/51/c1/198915b13e98b62a98f48309c41012638464651da755d941f4abe384c012/xgboost-0.82-py2.py3-none-win_amd64.whl (7.7MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\makra\\appdata\\roaming\\python\\python36\\site-packages (from xgboost) (1.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\makra\\anaconda3\\lib\\site-packages (from xgboost) (1.16.0)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.82\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/white-wine.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 1\n",
    "***\n",
    "### Instructions\n",
    "* Split the white-wine dataset into train and test set with `test_size = 0.3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "X , y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = tts(X,y,test_size=0.3,random_state =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 2\n",
    "***\n",
    "\n",
    "### Instructions\n",
    "* Initialise a decision tree model(Weak Classifier) with DecisionTreeClassifier() having max_depth=1 & random_state=0 and save it to a variable called `dt_clf`.\n",
    "\n",
    "* Fit the model on the training data `x_train` and `y_train` using the `fit()` method.\n",
    "\n",
    "* Find out the accuracy score between `x_test` and `y_test` using the `score()` method and save it in a variable called `dt_score`\n",
    "\n",
    "* Initialise a AdaBoost model with AdaBoostClassifier() having base_estimator=dt_clf & random_state=0 and save it to a variable called `ada_clf`.\n",
    "\n",
    "* Fit the model on the training data `x_train` and `y_train` using the `fit()` method.\n",
    "\n",
    "* Find out the accuracy score between `x_test` and `y_test` using the `score()` method and save it in a variable called `ada_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weak Learner Score:  0.42857142857142855\n",
      "Adaboost Score:  0.4326530612244898\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Fitting of Weak Classifier\n",
    "dt_clf = DecisionTreeClassifier(max_depth=1 , random_state=0)\n",
    "dt_clf.fit(x_train,y_train)\n",
    "dt_score = dt_clf.score(x_test,y_test)\n",
    "print(\"Weak Learner Score: \",dt_score)\n",
    "\n",
    "# Fitting of weak classifier with Adaboost\n",
    "ada_clf = AdaBoostClassifier(base_estimator=dt_clf , random_state=0)\n",
    "ada_clf.fit(x_train,y_train)\n",
    "ada_score = ada_clf.score(x_test,y_test)\n",
    "print(\"Adaboost Score: \",ada_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 3\n",
    "***\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Initialise a Gradient Boost model with GradientBoostingClassifier() having random_state=0 and save it to a variable called `gb_clf`.\n",
    "\n",
    "* Fit the model on the training data `x_train` and `y_train` using the `fit()` method.\n",
    "\n",
    "* Find out the accuracy score between `x_test` and `y_test` using the `score()` method and save it in a variable called `gb_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost Score:  0.5727891156462585\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state =0)\n",
    "gb_clf.fit(x_train,y_train)\n",
    "gb_score = gb_clf.score(x_test,y_test)\n",
    "print(\"Gradient Boost Score: \",gb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 4\n",
    "***\n",
    "### Instructions\n",
    "* For this challenge, you will have to install `xgboost` library. Import `xgboost` and instantiate `XGBClassifier()` and fit it on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier(random_state=0)\n",
    "\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 5\n",
    "***\n",
    "### Instructions\n",
    "* Predict the model on the test set and check the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5619047619047619"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 6\n",
    "***\n",
    "### Instructions\n",
    "* Now let's do some hyperparameter tuning by defining the parameters `'colsample_bytree': np.linspace(0.5, 0.9, 5)`,`'n_estimators':[5, 10]`,`'max_depth': [10, 15, 20, 25]` and then fit them into a GridSearchCV model with `scoring = 'neg_mean_squared_error'`and cross_ validation parameter `cv = 5`<br/><br/>Feel free to experiment on the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gbm_param_grid = {\n",
    "     'colsample_bytree': np.linspace(0.5, 0.9, 5),\n",
    "     'n_estimators':[5, 10],\n",
    "     'max_depth': [10, 15, 20, 25]\n",
    "}\n",
    "\n",
    "grid_mse = GridSearchCV(estimator = model, param_grid = gbm_param_grid, scoring = 'accuracy', cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 7\n",
    "***\n",
    "### Instructions\n",
    "* Fit the GridSearchCV model on the train dataset and get the best parametres and the Highest Accuracy found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'colsample_bytree': 0.6, 'max_depth': 25, 'n_estimators': 10}\n",
      "Highest Accuracy found:  0.6490665110851809\n"
     ]
    }
   ],
   "source": [
    "grid_mse.fit(x_train, y_train)\n",
    "print(\"Best parameters found: \",grid_mse.best_params_)\n",
    "print(\"Highest Accuracy found: \", grid_mse.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 8\n",
    "***\n",
    "### Instructions\n",
    "* Make a prediction on the test dataset and print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6482993197278911"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = grid_mse.predict(x_test)\n",
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/quiz.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank You\n",
    "***\n",
    "### Next Session: Challenges in ML\n",
    "For more queries - Reach out to academics@greyatom.com "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
