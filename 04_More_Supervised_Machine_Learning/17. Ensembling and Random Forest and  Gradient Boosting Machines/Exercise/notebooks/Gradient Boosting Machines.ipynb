{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align=\"center\">Gradient Boosting and XGBoost</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading https://files.pythonhosted.org/packages/51/c1/198915b13e98b62a98f48309c41012638464651da755d941f4abe384c012/xgboost-0.82-py2.py3-none-win_amd64.whl (7.7MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\makra\\appdata\\roaming\\python\\python36\\site-packages (from xgboost) (1.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\makra\\anaconda3\\lib\\site-packages (from xgboost) (1.16.0)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.82\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/white-wine.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 1\n",
    "***\n",
    "### Instructions\n",
    "* Split the white-wine dataset into train and test set with `test_size = 0.3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 2\n",
    "***\n",
    "\n",
    "### Instructions\n",
    "* Initialise a decision tree model(Weak Classifier) with DecisionTreeClassifier() having max_depth=1 & random_state=0 and save it to a variable called `dt_clf`.\n",
    "\n",
    "* Fit the model on the training data `x_train` and `y_train` using the `fit()` method.\n",
    "\n",
    "* Find out the accuracy score between `x_test` and `y_test` using the `score()` method and save it in a variable called `dt_score`\n",
    "\n",
    "* Initialise a AdaBoost model with AdaBoostClassifier() having base_estimator=dt_clf & random_state=0 and save it to a variable called `ada_clf`.\n",
    "\n",
    "* Fit the model on the training data `x_train` and `y_train` using the `fit()` method.\n",
    "\n",
    "* Find out the accuracy score between `x_test` and `y_test` using the `score()` method and save it in a variable called `ada_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 3\n",
    "***\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Initialise a Gradient Boost model with GradientBoostingClassifier() having random_state=0 and save it to a variable called `gb_clf`.\n",
    "\n",
    "* Fit the model on the training data `x_train` and `y_train` using the `fit()` method.\n",
    "\n",
    "* Find out the accuracy score between `x_test` and `y_test` using the `score()` method and save it in a variable called `gb_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 4\n",
    "***\n",
    "### Instructions\n",
    "* For this challenge, you will have to install `xgboost` library. Import `xgboost` and instantiate `XGBClassifier()` and fit it on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 5\n",
    "***\n",
    "### Instructions\n",
    "* Predict the model on the test set and check the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 6\n",
    "***\n",
    "### Instructions\n",
    "* Now let's do some hyperparameter tuning by defining the parameters `'colsample_bytree': np.linspace(0.5, 0.9, 5)`,`'n_estimators':[5, 10]`,`'max_depth': [10, 15, 20, 25]` and then fit them into a GridSearchCV model with `scoring = 'neg_mean_squared_error'`and cross_ validation parameter `cv = 5`<br/><br/>Feel free to experiment on the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 7\n",
    "***\n",
    "### Instructions\n",
    "* Fit the GridSearchCV model on the train dataset and get the best parametres and the Highest Accuracy found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 8\n",
    "***\n",
    "### Instructions\n",
    "* Make a prediction on the test dataset and print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/quiz.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "# Gradient Boosting Machines\n",
    "***\n",
    "```python\n",
    "Q1. Which of the following is true about “max_depth” hyperparameter in Gradient Boosting?\n",
    "\n",
    "Lower is better parameter in case of same validation accuracy\n",
    "Higher is better parameter in case of same validation accuracy\n",
    "Increase the value of max_depth may overfit the data\n",
    "Increase the value of max_depth may underfit the data\n",
    "A) 1 and 3\n",
    "B) 1 and 4\n",
    "C) 2 and 3\n",
    "D) 2 and 4\n",
    "\n",
    "\n",
    "Increase the depth from the certain value of depth may overfit the data and for 2 depth values validation accuracies are same we always prefer the small depth in final model building.\n",
    "```\n",
    "```python\n",
    "Q2. Which of the following algorithm doesn’t uses learning Rate as of one of its hyperparameter?\n",
    "\n",
    "Gradient Boosting\n",
    "Extra Trees\n",
    "AdaBoost\n",
    "Random Forest\n",
    "A) 1 and 3\n",
    "B) 1 and 4\n",
    "C) 2 and 3\n",
    "D) 2 and 4\n",
    "\n",
    "\n",
    "Random Forest and Extra Trees don’t have learning rate as a hyperparameter.\n",
    "```\n",
    "```python\n",
    "Q3. Which of the following is true about the Gradient Boosting trees?\n",
    "\n",
    "In each stage, introduce a new regression tree to compensate the shortcomings of existing model\n",
    "We can use gradient decent method for minimize the loss function\n",
    "A) 1\n",
    "B) 2\n",
    "C) 1 and 2\n",
    "D) None of these\n",
    "\n",
    "\n",
    "Both are true and self explanatory\n",
    "```\n",
    "```python\n",
    "Q4. In greadient boosting it is important use learning rate to get optimum output. Which of the following is true abut choosing the learning rate?\n",
    "\n",
    "A) Learning rate should be as high as possible\n",
    "B) Learning Rate should be as low as possible\n",
    "C) Learning Rate should be low but it should not be very low\n",
    "D) Learning rate should be high but it should not be very high\n",
    "\n",
    "\n",
    "\n",
    "Learning rate should be low but it should not be very low otherwise algorithm will take so long to finish the training because you need to increase the number trees.\n",
    "```\n",
    "```python\n",
    "Q5. [True or False] Cross validation can be used to select the number of iterations in boosting; this procedure may help reduce overfitting.\n",
    "\n",
    "A) TRUE\n",
    "B) FALSE\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank You\n",
    "***\n",
    "### Next Session: Challenges in ML\n",
    "For more queries - Reach out to academics@greyatom.com "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
