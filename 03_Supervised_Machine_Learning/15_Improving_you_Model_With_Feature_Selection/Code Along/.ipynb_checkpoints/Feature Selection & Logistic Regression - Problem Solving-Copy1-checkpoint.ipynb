{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data file contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "The data set, (data1.csv) has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "You can read more about dataset [Here](https://www.kaggle.com/c/digit-recognizer/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/icon/ppt-icons.png' alt='Mini-Challenge' style=\"width: 100px;float:left; margin-right:15px\"/><br/>\n",
    "\n",
    "## Mini-Challenge - 1\n",
    "***\n",
    "### Instructions\n",
    "\n",
    "- Store all the features(independent values) in a variable called `X`\n",
    "- Store the target variable `label`(dependent value) in a variable called `y`\n",
    "- Split the data X and y into X_train,X_test,y_train and y_test in the ratio 70:30 and `random_state = 42`\n",
    "- Further split the testing data into X_train1, X_test1, y_train1, y_test1 in 70:30 ratio, `stratify = y_test` and \n",
    "  random_state = 101 \n",
    "- Then apply the base Logistic regression model pass parameter as `random_state=101` and calculate the `score` on new splitted \n",
    "  test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.8436507936507937\n",
      "Wall time: 4min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Dividing the training set in train and test set\n",
    "y = df.iloc[:,0]\n",
    "X = df.iloc[:,1:]\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_test, y_test, test_size=0.3,stratify=y_test, random_state = 101)\n",
    "\n",
    "lr = LogisticRegression(random_state=101)\n",
    "lr.fit(X_train1,y_train1)\n",
    "print(\"Accuracy on test data:\", lr.score(X_test1,y_test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:  Logistic Regression without any Feature Selection gives an accuracy of 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/icon/ppt-icons.png' alt='Mini-Challenge' style=\"width: 100px;float:left; margin-right:15px\"/><br/>\n",
    "\n",
    "## Mini-Challenge - 2\n",
    "***\n",
    "**Remove Correlated Features**\n",
    "As we have learned earlier one of the assumptions of Logistic Regression model is that the independent features should not be correlated to each other(i.e Multicollinearity).\n",
    "### Instructions\n",
    "\n",
    "* Find the features that have a correlation higher that 0.8 and remove the same so that the assumption for logistic regression model is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to be dropped: \n",
      "['pixel13', 'pixel15', 'pixel33', 'pixel35', 'pixel86', 'pixel121', 'pixel122', 'pixel123', 'pixel124', 'pixel125', 'pixel126', 'pixel127', 'pixel128', 'pixel148', 'pixel149', 'pixel150', 'pixel151', 'pixel152', 'pixel153', 'pixel154', 'pixel155', 'pixel156', 'pixel157', 'pixel158', 'pixel159', 'pixel176', 'pixel177', 'pixel178', 'pixel179', 'pixel180', 'pixel181', 'pixel182', 'pixel183', 'pixel184', 'pixel244', 'pixel245', 'pixel271', 'pixel272', 'pixel273', 'pixel274', 'pixel280', 'pixel286', 'pixel287', 'pixel288', 'pixel289', 'pixel298', 'pixel299', 'pixel300', 'pixel301', 'pixel302', 'pixel314', 'pixel315', 'pixel316', 'pixel317', 'pixel326', 'pixel327', 'pixel328', 'pixel329', 'pixel330', 'pixel331', 'pixel336', 'pixel341', 'pixel342', 'pixel343', 'pixel344', 'pixel345', 'pixel346', 'pixel351', 'pixel354', 'pixel355', 'pixel356', 'pixel357', 'pixel358', 'pixel359', 'pixel368', 'pixel369', 'pixel370', 'pixel371', 'pixel372', 'pixel373', 'pixel374', 'pixel378', 'pixel379', 'pixel383', 'pixel384', 'pixel385', 'pixel386', 'pixel387', 'pixel388', 'pixel393', 'pixel397', 'pixel398', 'pixel399', 'pixel400', 'pixel401', 'pixel406', 'pixel411', 'pixel412', 'pixel413', 'pixel414', 'pixel415', 'pixel416', 'pixel424', 'pixel425', 'pixel426', 'pixel427', 'pixel428', 'pixel429', 'pixel434', 'pixel439', 'pixel440', 'pixel441', 'pixel442', 'pixel443', 'pixel444', 'pixel453', 'pixel454', 'pixel455', 'pixel456', 'pixel461', 'pixel462', 'pixel466', 'pixel467', 'pixel468', 'pixel469', 'pixel470', 'pixel471', 'pixel472', 'pixel480', 'pixel481', 'pixel482', 'pixel483', 'pixel484', 'pixel492', 'pixel493', 'pixel494', 'pixel495', 'pixel496', 'pixel497', 'pixel498', 'pixel499', 'pixel508', 'pixel509', 'pixel510', 'pixel511', 'pixel512', 'pixel519', 'pixel522', 'pixel523', 'pixel524', 'pixel525', 'pixel526', 'pixel533', 'pixel536', 'pixel537', 'pixel538', 'pixel539', 'pixel540', 'pixel541', 'pixel550', 'pixel551', 'pixel552', 'pixel553', 'pixel554', 'pixel564', 'pixel565', 'pixel566', 'pixel567', 'pixel568', 'pixel569', 'pixel579', 'pixel580', 'pixel581', 'pixel589', 'pixel592', 'pixel593', 'pixel594', 'pixel595', 'pixel596', 'pixel597', 'pixel598', 'pixel607', 'pixel608', 'pixel616', 'pixel617', 'pixel622', 'pixel623', 'pixel624', 'pixel625', 'pixel626', 'pixel627', 'pixel628', 'pixel643', 'pixel652', 'pixel653', 'pixel654', 'pixel655', 'pixel656', 'pixel681', 'pixel682', 'pixel683', 'pixel725', 'pixel726', 'pixel779']\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = df.drop(\"label\",1).corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.8\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "print(\"Columns to be dropped: \")\n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the updated dataframe df after removing correlated features in variable df1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 581)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 581 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel773  pixel774  pixel775  pixel776  pixel777  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel778  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 581 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.copy()\n",
    "print(df1.shape)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/icon/ppt-icons.png' alt='Mini-Challenge' style=\"width: 100px;float:left; margin-right:15px\"/><br/>\n",
    "\n",
    "## Mini-Challenge - 3\n",
    "***\n",
    "### Instructions\n",
    "- Apply Logistic Regression model on a newly created dataframe df1\n",
    "- Store all the features(independent values) in a variable called `X`\n",
    "- Store the target variable `label`(dependent value) in a variable called `y`\n",
    "- Split the data X and y into X_train,X_test,y_train and y_test in the ratio 70:30, `stratify=y` and `random_state = 42`\n",
    "- Further split the testing data into X_train1, X_test1, y_train1, y_test1 in 70:30 ratio, `stratify = y_test` and \n",
    "  `random_state = 101` \n",
    "- Then apply the base Logistic regression model pass parameter as `random_state=101` and calculate the `score` on new splitted \n",
    "  test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data:  0.8481481481481481\n",
      "Wall time: 4min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "y = df1.iloc[:,0]\n",
    "X = df1.iloc[:,1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y, random_state = 42)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_test, y_test, test_size=0.3,stratify=y_test, random_state = 101)\n",
    "lr = LogisticRegression(random_state=101)\n",
    "lr.fit(X_train1,y_train1)\n",
    "print(\"Accuracy on test data: \", lr.score(X_test1,y_test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation: After keeping highly correlated features, there is not much change in the score. Lets apply another feature selection technique(Chi Squared test)to see whether we can increase our score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/icon/ppt-icons.png' alt='Mini-Challenge' style=\"width: 100px;float:left; margin-right:15px\"/><br/>\n",
    "\n",
    "## Mini-Challenge - 4\n",
    "***\n",
    "Chi-Square test:\n",
    "In this task we will try to identify the optimum no. of features to use\n",
    "### Instructions\n",
    "\n",
    "* Store all the features(independent values) in a variable called `X`\n",
    "* Store the target variable `label`(dependent value) in a variable called `y`\n",
    "* Three variables `nof_list`, `high_score` and `nof` are already defined for you(Feel free to change the number of features in `nof_list`)\n",
    "* Run a `n` loop passing through each element of `nof_list`.\n",
    "* Inside the loop, initialise a `SelectKBest()` with the parameters `score_func=chi2` & `k= n` and save it to a variable called `test`.\n",
    "* Split `X` and `y` into `X_train,X_test,y_train,y_test` using train_test_split() function. Use `test_size = 0.3`,`stratify=y`   and `random_state = 42`\n",
    "* Further split the testing data into X_train1, X_test1, y_train1, y_test1 in 70:30 ratio, `stratify = y_test` and  `random_state = 101`\n",
    "* Fit `test` on the training data `X_train1` and `y_train1` using the `fit_transform()` method. Store the result back into `X_train1`\n",
    "* Transform `X_test1` using the `transform()` method of test. Store the result back into `X_test1`\n",
    "* Initialise a logistic regression model with LogisticRegression(random_state=101) and save it to a variable called `model`.\n",
    "* Fit the model on the training data `X_train1` and `y_train1` using the `fit()` method.\n",
    "* Write a condition to store the highest R2 score of all `n`. Store the highest R2 score in `high score` and the \n",
    "  `n` assosciated with it in `nof`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Score is: 0.8597883597883598 with features= 300\n",
      "Wall time: 4min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "y = df1.iloc[:,0]\n",
    "X = df1.iloc[:,1:]\n",
    "\n",
    "nof_list=[100,300]\n",
    "\n",
    "high_score=0\n",
    "\n",
    "nof=0\n",
    "\n",
    "for n in nof_list:\n",
    "    test = SelectKBest(score_func=chi2 , k= n )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y, random_state = 42)\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(X_test, y_test, test_size=0.3,stratify=y_test, random_state = 101)\n",
    "    X_train1 = test.fit_transform(X_train1,y_train1)\n",
    "    X_test1 = test.transform(X_test1)\n",
    "    \n",
    "    model = LogisticRegression(random_state=101)\n",
    "    model.fit(X_train1,y_train1)\n",
    "    \n",
    "    if model.score(X_test1,y_test1)>high_score:\n",
    "        high_score=model.score(X_test1,y_test1)\n",
    "        nof=n \n",
    "print(\"High Score is:\",high_score, \"with features=\",nof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation: We observe that using chi squared test there is a 1% change in the score and the optimum features that we got is 300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/icon/ppt-icons.png' alt='Mini-Challenge' style=\"width: 100px;float:left; margin-right:15px\"/><br/>\n",
    "\n",
    "## Mini-Challenge - 5\n",
    "***\n",
    "Analysis of variance (ANOVA) is another method to check for close relationship between two variables.\n",
    "### Instructions\n",
    "\n",
    "* Store all the features(independent values) in a variable called `X`\n",
    "* Store the target variable `label`(dependent value) in a variable called `y`\n",
    "* Three variables `nof_list`, `high_score` and `nof` are already defined for you(Feel free to change the number of features in `nof_list`)\n",
    "* Run a `n` loop passing through each element of `nof_list`.\n",
    "* Inside the loop, initialise a `SelectKBest()` with the parameters `score_func=f_classif` & `k= n` and save it to a variable called `test`.\n",
    "* Split `X` and `y` into `X_train,X_test,y_train,y_test` using train_test_split() function. Use `test_size = 0.3`,`stratify=y`   and `random_state = 42`\n",
    "* Further split the testing data into X_train1, X_test1, y_train1, y_test1 in 70:30 ratio, `stratify = y_test` and  `random_state = 101`\n",
    "* Fit `test` on the training data `X_train1` and `y_train1` using the `fit_transform()` method. Store the result back into `X_train1`\n",
    "* Transform `X_test1` using the `transform()` method of test. Store the result back into `X_test1`\n",
    "* Initialise a logistic regression model with LogisticRegression(random_state=101) and save it to a variable called `model`.\n",
    "* Fit the model on the training data `X_train1` and `y_train1` using the `fit()` method.\n",
    "* Write a condition to store the highest R2 score of all `n`. Store the highest R2 score in `high score` and the \n",
    "  `n` assosciated with it in `nof`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Score is: 0.8632275132275132 with features= 300\n",
      "Wall time: 4min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "y = data.iloc[:,0]\n",
    "X = data.iloc[:,1:]\n",
    "\n",
    "nof_list=[50,300]\n",
    "\n",
    "high_score=0\n",
    "\n",
    "nof=0\n",
    "\n",
    "\n",
    "for n in nof_list:\n",
    "    test = SelectKBest(score_func=f_classif , k= n )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y, random_state = 42)\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(X_test, y_test, test_size=0.3,stratify=y_test, random_state = 101)\n",
    "    X_train1 = test.fit_transform(X_train1,y_train1)\n",
    "    X_test1 = test.transform(X_test1)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train1,y_train1)\n",
    "\n",
    "    if model.score(X_test1,y_test1)>high_score:\n",
    "        high_score=model.score(X_test1,y_test1)\n",
    "        nof=n \n",
    "print(\"High Score is:\",high_score, \"with features=\",nof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation: We observe that using Anova test there is not much change in the score i.e 0.86 and the optimum features that we got is 300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/icon/ppt-icons.png' alt='Mini-Challenge' style=\"width: 100px;float:left; margin-right:15px\"/><br/>\n",
    "\n",
    "## Mini-Challenge - 6\n",
    "***\n",
    "Applying PCA feature reduction technique\n",
    "\n",
    "### Instructions\n",
    "* Store all the features(independent values) in a variable called `X` from `df1`\n",
    "* Store the target variable `label`(dependent value) in a variable called `y`\n",
    "* Split `X` and `y` into `X_train,X_test,y_train,y_test` using train_test_split() function. Use `test_size = 0.3`,`stratify=y`   and `random_state = 42`\n",
    "* Further split the testing data into X_train1, X_test1, y_train1, y_test1 in 70:30 ratio, `stratify = y_test` and  `random_state = 101`\n",
    "* Initialise a PCA model with PCA(.95) and save it to a variable called `pca`.\n",
    "* Fit the pca on the training data `X_train1` using the `fit()` method.\n",
    "* Print the no of components of the pca method\n",
    "* Transform `X_train1`, `X_test1` using the `transform()` method of pca. Store the result back into `X_train1` and `X_test1`\n",
    "  simultaneously.\n",
    "* Initialize a logistic regression model  with `Logisticregression(solver='lbfgs')` and save it to a variable called logistic.\n",
    "* Fit the logistic on the training data `X_train1` and `y_train1` using the `fit()` method.\n",
    "* Predict on `X_test1` for one Observation and print it\n",
    "* Calculate the score on the test data\n",
    "* You can also compare your predicted values and observed values by printing out values of `logistic.predict(X_test1)` and  `y_test1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Components used:  106\n",
      "Prediction for one observation:  [2]\n",
      "Prediction for 10 observation:  [2 0 6 5 6 8 3 5 0 3]\n",
      "Accuracy after applying PCA:  0.8751322751322751\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Make an instance of the Model\n",
    "y = df1.iloc[:,0]\n",
    "X = df1.iloc[:,1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y, random_state = 42)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_test, y_test, test_size=0.3,stratify=y_test, random_state = 101)\n",
    "\n",
    "pca = PCA(.95)\n",
    "\n",
    "\n",
    "pca.fit(X_train1)\n",
    "print(\"No of Components used: \",pca.n_components_)\n",
    "\n",
    "X_train1 = pca.transform(X_train1)\n",
    "X_test1 = pca.transform(X_test1)\n",
    "\n",
    "\n",
    "logistic = LogisticRegression(solver = 'lbfgs')\n",
    "logistic.fit(X_train1, y_train1)\n",
    "\n",
    "# Predict for One Observation \n",
    "print(\"Prediction for one observation: \",logistic.predict(X_test1[0].reshape(1,-1)))\n",
    "\n",
    "# Predict for ten Observation \n",
    "print(\"Prediction for 10 observation: \",logistic.predict(X_test1[0:10]))\n",
    "\n",
    "print(\"Accuracy after applying PCA: \",logistic.score(X_test1, y_test1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for 10 observation:     [2 0 6 5 6 8 3 5 0 3]\n",
      "Actual values for 10 observation:  [3 0 6 5 6 8 3 5 0 3]\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction for 10 observation:    \",logistic.predict(X_test1[0:10]))\n",
    "print(\"Actual values for 10 observation: \",y_test1[0:10].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/icon/quiz.png' alt='Mini-Challenge' style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br/>\n",
    "\n",
    "### Feature Selection & Logistic Regression\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
