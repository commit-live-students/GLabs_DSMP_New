{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align=\"center\">Feature Selection</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainer Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\makra\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py:689: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://player.vimeo.com/video/283692067\" width=\"800\" height=\"600\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe src=\"https://player.vimeo.com/video/283692067\" width=\"800\" height=\"600\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>...</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>261.88</td>\n",
       "      <td>1</td>\n",
       "      <td>64598</td>\n",
       "      <td>0</td>\n",
       "      <td>33000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>632.47</td>\n",
       "      <td>113.7204</td>\n",
       "      <td>276.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15949.0</td>\n",
       "      <td>20800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20800.0</td>\n",
       "      <td>20800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>706.16</td>\n",
       "      <td>1</td>\n",
       "      <td>63724</td>\n",
       "      <td>4</td>\n",
       "      <td>81500.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13334.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23473.0</td>\n",
       "      <td>43100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>321.13</td>\n",
       "      <td>1</td>\n",
       "      <td>72661</td>\n",
       "      <td>0</td>\n",
       "      <td>102000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>320.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39143.0</td>\n",
       "      <td>22300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11500.0</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>323.54</td>\n",
       "      <td>4</td>\n",
       "      <td>78022</td>\n",
       "      <td>4</td>\n",
       "      <td>32760.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4874.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>24724.0</td>\n",
       "      <td>14100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>476.30</td>\n",
       "      <td>0</td>\n",
       "      <td>100018</td>\n",
       "      <td>0</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>476.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>272492.0</td>\n",
       "      <td>15400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  funded_amnt  term  int_rate  installment  grade  emp_title  \\\n",
       "0     8000.0       8000.0     0        19       261.88      1      64598   \n",
       "1    20800.0      20800.0     0        33       706.16      1      63724   \n",
       "2    10000.0      10000.0     0        10       321.13      1      72661   \n",
       "3    11500.0      11500.0     1       112       323.54      4      78022   \n",
       "4    15000.0      15000.0     0         8       476.30      0     100018   \n",
       "\n",
       "   home_ownership  annual_inc  verification_status        ...         \\\n",
       "0               0     33000.0                    0        ...          \n",
       "1               4     81500.0                    2        ...          \n",
       "2               0    102000.0                    0        ...          \n",
       "3               4     32760.0                    2        ...          \n",
       "4               0     63000.0                    0        ...          \n",
       "\n",
       "   total_acc  total_rec_late_fee  recoveries  collection_recovery_fee  \\\n",
       "0       16.0                15.0      632.47                 113.7204   \n",
       "1       41.0                 0.0        0.00                   0.0000   \n",
       "2       22.0                 0.0        0.00                   0.0000   \n",
       "3       17.0                 0.0        0.00                   0.0000   \n",
       "4       29.0                 0.0        0.00                   0.0000   \n",
       "\n",
       "   last_pymnt_amnt  collections_12_mths_ex_med  acc_now_delinq  tot_coll_amt  \\\n",
       "0           276.88                         0.0             0.0           0.0   \n",
       "1         13334.93                         0.0             0.0           0.0   \n",
       "2           320.91                         0.0             0.0           0.0   \n",
       "3          4874.03                         0.0             0.0          92.0   \n",
       "4           476.23                         0.0             0.0        1514.0   \n",
       "\n",
       "   tot_cur_bal  total_rev_hi_lim  \n",
       "0      15949.0           20800.0  \n",
       "1      23473.0           43100.0  \n",
       "2      39143.0           22300.0  \n",
       "3      24724.0           14100.0  \n",
       "4     272492.0           15400.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('../data/lending.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression without any Feature Selection  we get an accuracy of 0.95.\n",
    "**Input**\n",
    "\n",
    "```python\n",
    "X = df.drop('loan_status',1)\n",
    "y= df['loan_status'].copy()\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size = 0.3 , random_state = 42)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "print(\"Accuracy:\", model.score(X_test,y_test))\n",
    "```\n",
    "\n",
    "**Output**\n",
    "\n",
    "```python\n",
    "Accuracy: 0.9533965104950846\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Correlated Features\n",
    "As we have learned earlier one of the assumptions of Logistic Regression model is that the independent features should not be correlated to each other(i.e Multicollinearity).We will find the features that have a correlation higher that 0.75 and remove the same so that the assumption for logistic regression model is satisfied.\n",
    "\n",
    "**Input**\n",
    "```python \n",
    "# Create correlation matrix\n",
    "corr_matrix = df.drop(\"loan_status\",1).corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "print(to_drop)\n",
    "\n",
    "# Dropping the high correlated features\n",
    "print(\"Columns to be dropped: \")\n",
    "df.drop(to_drop,axis=1,inplace=True)\n",
    "```\n",
    "**Output**\n",
    "```python\n",
    "Columns to be dropped:\n",
    "['funded_amnt',\n",
    " 'installment',\n",
    " 'grade',\n",
    " 'collection_recovery_fee',\n",
    " 'total_rev_hi_lim']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to be dropped: \n",
      "['funded_amnt', 'installment', 'grade', 'collection_recovery_fee', 'total_rev_hi_lim']\n"
     ]
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = df.drop(\"loan_status\",1).corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "print(\"Columns to be dropped: \")\n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/icon/ppt-icons.png' alt='Mini-Challenge' style=\"width: 100px;float:left; margin-right:15px\"/><br/>\n",
    "\n",
    "## Mini-Challenge - 1\n",
    "***\n",
    "### Instructions\n",
    "* Apply Logistic Regression model on a newly created dataframe `df`\n",
    "* Store all the features(independent values) in a variable called `X`\n",
    "* Store the target variable `loan_status`(dependent value) in a variable called `y`\n",
    "* Split `X and y` into `X_train,X_test,y_train,y_test` using `train_test_split()` function. Use `test_size = 0.3`     and `random_state = 42`\n",
    "* Instantiate a Logistic regression model with `LogisticRegression()` and save it to a variable called `model`.\n",
    "* Fit the model on the training data `X_train` and `y_train`.\n",
    "* Calculate the `score` of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/icon/ppt-icons.png' alt='Mini-Challenge' style=\"width: 100px;float:left; margin-right:15px\"/><br/>\n",
    "\n",
    "## Mini-Challenge - 2\n",
    "***\n",
    "Chi-Square test:\n",
    "In this task we will also try to identify the optimum no. of features to use\n",
    "### Instructions\n",
    "\n",
    "* Store all the features(independent values) in a variable called `X`\n",
    "* Store the target variable `loan_status`(dependent value) in a variable called `y`\n",
    "* Three variables `nof_list`, `high_score` and `nof` are already defined for you.\n",
    "* Run a `n` loop passing through each element of `nof_list`.\n",
    "* Inside the loop, initialise a `SelectKBest()` with the parameters `score_func=chi2` & `k= n` and save it to a variable called `test`.\n",
    "* Split `X` and `y` into `X_train,X_test,y_train,y_test` using train_test_split() function. Use `test_size = 0.3` and `random_state = 42`\n",
    "* Fit `test` on the training data `X_train` and `y_train` using the `fit_transform()` method. Store the result back into `X_train`\n",
    "* Transform `X_test` using the `transform()` method of test .Store the result back into `X_test`\n",
    "* Initialise a logistic regression model with LogisticRegression() and save it to a variable called `model`.\n",
    "* Fit the model on the training data `X_train` and `y_train` using the 'fit()' method.\n",
    "* Write a condition to store the highest R2 score of all `n`. Store the highest R2 score in `high score` and the \n",
    "  `n` assosciated with it in `nof`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/icon/ppt-icons.png' alt='Mini-Challenge' style=\"width: 100px;float:left; margin-right:15px\"/><br/>\n",
    "\n",
    "## Mini-Challenge - 3\n",
    "***\n",
    "Analysis of variance (ANOVA) is another method to check for close relationship between two variables.\n",
    "### Instructions\n",
    "* Store all the features(independent values) in a variable called `X`\n",
    "* Store the target variable `loan_status`(dependent value) in a variable called `y`\n",
    "* Three variables `nof_list`, `high_score` and `nof` are already defined for you.\n",
    "* Run a `n` loop passing through each element of `nof_list`.\n",
    "* Inside the loop, initialise a `SelectKBest()` with the parameters `score_func=f_classif` & `k= n` and save it to a variable called `test`.\n",
    "* Split `X` and `y` into `X_train,X_test,y_train,y_test` using train_test_split() function. Use `test_size = 0.3` and `random_state = 42`\n",
    "* Fit `test` on the training data `X_train` and `y_train` using the `fit_transform()` method. Store the result back into `X_train`\n",
    "* Transform `X_test` using the `transform()` method of test .Store the result back into `X_test`\n",
    "* Initialise a logistic regression model with LogisticRegression() and save it to a variable called `model`.\n",
    "* Fit the model on the training data `X_train` and `y_train` using the 'fit()' method.\n",
    "* Write a condition to store the highest R2 score of all `n`. Store the highest R2 score in `high score` and the \n",
    "  `n` assosciated with it in `nof`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/icon/ppt-icons.png' alt='Mini-Challenge' style=\"width: 100px;float:left; margin-right:15px\"/><br/>\n",
    "\n",
    "## Mini-Challenge - 4\n",
    "***\n",
    "Recursive Feature Elimination\n",
    "### Instructions\n",
    "* Let's now try to implement RFE and see the score in the Lending Loan dataset.\n",
    "* In this task we will also try to identify the optimum no. of features to use\n",
    "* Store all the features(independent values) in a variable called `X`\n",
    "* Store the target variable `loan_status`(dependent value) in a variable called `y`\n",
    "* Three variables `nof_list`, `high_score` and `nof` are already defined for you.\n",
    "* Run a `n` loop passing through each element of `nof_list`.\n",
    "* Inside the loop, split `X` and `y` into `X_train,X_test,y_train,y_test` using train_test_split() function. Use `test_size = 0.3` and `random_state = 42`\n",
    "* Initialise a logistic regression model with LogisticRegression() and save it to a variable called `model`.\n",
    "* Initialise a RFE() object with parameters `model` & `n` and store it to a variable called `rfe`.\n",
    "* Fit `rfe` on the training data `X_train` and `y_train` using the `fit_transform()` method. Store the result into `X_train_rfe`\n",
    "* Transform `X_test` using the `transform()` method of `rfe` .Store the result into `X_test_rfe`\n",
    "* Fit the model on the training data `X_train_rfe` and `y_train` using the `fit()` method.\n",
    "* Write a condition to store the highest R2 score of all `n`. Store the highest R2 score in `high score` and the \n",
    "  `n` assosciated with it in `nof`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/icon/ppt-icons.png' alt='Mini-Challenge' style=\"width: 100px;float:left; margin-right:15px\"/><br/>\n",
    "\n",
    "## Mini-Challenge - 5\n",
    "***\n",
    "### Instructions\n",
    "* Now determine the selected features and also the ranking of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/icon/ppt-icons.png' alt='Mini-Challenge' style=\"width: 100px;float:left; margin-right:15px\"/><br/>\n",
    "\n",
    "## Mini-Challenge - 6\n",
    "***\n",
    "### Instructions\n",
    "* The above assignment does not enlist the features to be selected. Select all the column names and the selected features above and arrange them in their respective order appropriately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/icon/ppt-icons.png' alt='Mini-Challenge' style=\"width: 100px;float:left; margin-right:15px\"/><br/>\n",
    "\n",
    "## Mini-Challenge - 7\n",
    "***\n",
    "### Instructions\n",
    "* Plot a heatmap depicting the correlation between variables in the Student Performance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/icon/quiz.png' alt='Mini-Challenge' style=\"width: 100px;float:left; margin-right:15px\"/><br/>\n",
    "\n",
    "### Feature Selection \n",
    "\n",
    "***\n",
    "\n",
    "Q1.  Which of the following is NOT a benefit of the sparsity imposed by the Lasso?\n",
    "```python\n",
    "a. Sparse models are generally more easy to interperet\n",
    "b. The Lasso does variable selection by default\n",
    "c. Using the Lasso penalty helps to decrease the bias of the fits correct\n",
    "d. Using the Lasso penalty helps to decrease the variance of the fits\n",
    "```\n",
    "Q2. Which of the following methods uses the classifier performance for feature selection?\n",
    "\n",
    "```python \n",
    "a. filter\n",
    "b. wrapper\n",
    "c. embedded\n",
    "\n",
    "```\n",
    "Q3.Which of the below statement is True? \n",
    "Statement 1: Filter methods measure the relevance of features by their correlation with dependent variable while wrapper  methods measure the usefulness of a subset of feature by actually training a model on it.\n",
    "Statement 2: Filter methods are much faster compared to wrapper methods as they do not involve training the models. On the other hand, wrapper methods are computationally very expensive as well.\n",
    "```python\n",
    "a. Both are True\n",
    "b. Both are False\n",
    "c. Statement 1 is True, Statement 2 is False\n",
    "d. Statement 2 is True, Statement 1 is False\n",
    "\n",
    "```\n",
    "\n",
    "Q4. Which of the following methods is used to find correlation between continous features and target?\n",
    "```python\n",
    "a. Pearson\n",
    "b. LDA\n",
    "c. Chi Square\n",
    "d. Anova\n",
    "\n",
    "```\n",
    "Q5. The following is the equation for Ridge Regression. Now as we increase the value of $\\lambda$ from 0, the bias will?\n",
    "\n",
    "\n",
    "\n",
    "![](../images/icon/Ridge.png)\n",
    "\n",
    "\n",
    "```python\n",
    "a. Steadily increase\n",
    "b. Remains constant\n",
    "c. Steadily decrease\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank You\n",
    "***\n",
    "### Next Session: Decision Tree\n",
    "For more queries - Reach out to academics@greyatom.com "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
